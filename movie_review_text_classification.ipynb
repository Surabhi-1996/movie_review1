{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie_review_text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiJc0cHaFoA7"
      },
      "source": [
        "**Text Classification Project**\n",
        "\n",
        "In this exercise we'll try to develop a classification model - that is, we'll try to predict the Positive/Negative labels based on text content alone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etxU6nCRGH4z"
      },
      "source": [
        "**Perform imports and load the dataset**\n",
        "\n",
        "The dataset contains the text of 2000 movie reviews. 1000 are positive, 1000 are negative, and the text has been preprocessed as a tab-delimited file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er-yADkgFyuv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8-v1MuuGXcM"
      },
      "source": [
        "df = pd.read_csv(\"moviereviews.tsv\",sep=\"\\t\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "qkMaMqPyG1zy",
        "outputId": "4de90139-1050-4e63-ff1e-cfcdfd7ae9ba"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>how do films like mouse hunt get into theatres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>some talented actresses are blessed with a dem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>this has been an extraordinary year for austra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pos</td>\n",
              "      <td>according to hollywood movies made in last few...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>my first press screening of 1998 and already i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                             review\n",
              "0   neg  how do films like mouse hunt get into theatres...\n",
              "1   neg  some talented actresses are blessed with a dem...\n",
              "2   pos  this has been an extraordinary year for austra...\n",
              "3   pos  according to hollywood movies made in last few...\n",
              "4   neg  my first press screening of 1998 and already i..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UQVNaXxIEiv",
        "outputId": "6cf52fb7-bbb5-4961-fb24-80415b923cac"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "aIBCZRlHG4uB",
        "outputId": "857f1097-d56a-45d9-b82a-087ca2dd661c"
      },
      "source": [
        "df[\"review\"][0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'how do films like mouse hunt get into theatres ? \\r\\nisn\\'t there a law or something ? \\r\\nthis diabolical load of claptrap from steven speilberg\\'s dreamworks studio is hollywood family fare at its deadly worst . \\r\\nmouse hunt takes the bare threads of a plot and tries to prop it up with overacting and flat-out stupid slapstick that makes comedies like jingle all the way look decent by comparison . \\r\\nwriter adam rifkin and director gore verbinski are the names chiefly responsible for this swill . \\r\\nthe plot , for what its worth , concerns two brothers ( nathan lane and an appalling lee evens ) who inherit a poorly run string factory and a seemingly worthless house from their eccentric father . \\r\\ndeciding to check out the long-abandoned house , they soon learn that it\\'s worth a fortune and set about selling it in auction to the highest bidder . \\r\\nbut battling them at every turn is a very smart mouse , happy with his run-down little abode and wanting it to stay that way . \\r\\nthe story alternates between unfunny scenes of the brothers bickering over what to do with their inheritance and endless action sequences as the two take on their increasingly determined furry foe . \\r\\nwhatever promise the film starts with soon deteriorates into boring dialogue , terrible overacting , and increasingly uninspired slapstick that becomes all sound and fury , signifying nothing . \\r\\nthe script becomes so unspeakably bad that the best line poor lee evens can utter after another run in with the rodent is : \" i hate that mouse \" . \\r\\noh cringe ! \\r\\nthis is home alone all over again , and ten times worse . \\r\\none touching scene early on is worth mentioning . \\r\\nwe follow the mouse through a maze of walls and pipes until he arrives at his makeshift abode somewhere in a wall . \\r\\nhe jumps into a tiny bed , pulls up a makeshift sheet and snuggles up to sleep , seemingly happy and just wanting to be left alone . \\r\\nit\\'s a magical little moment in an otherwise soulless film . \\r\\na message to speilberg : if you want dreamworks to be associated with some kind of artistic credibility , then either give all concerned in mouse hunt a swift kick up the arse or hire yourself some decent writers and directors . \\r\\nthis kind of rubbish will just not do at all . \\r\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOakTxMHIU50"
      },
      "source": [
        "**Check for missing values:**\n",
        " \n",
        "Detect & remove NaN values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owWYtS4YG5qH",
        "outputId": "b0616b85-5815-43ee-fa80-2e78d2001940"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label      0\n",
              "review    35\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUA7c_rQI7rT"
      },
      "source": [
        "35 records show NaN. These are easily removed using the .dropna() pandas function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yLqxCf3HFEd"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qQooImCHI9f",
        "outputId": "8009ccd9-8054-4855-9e29-34a05ff9e1a0"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label     0\n",
              "review    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZTW9k9UJOIk"
      },
      "source": [
        "**Detect & remove empty strings**\n",
        "\n",
        "Technically, we're dealing with \"whitespace only\" strings. If the original .tsv file had contained empty strings, pandas .read_csv() would have assigned NaN values to those cells by default.\n",
        "\n",
        "In order to detect these strings we need to iterate over each row in the DataFrame. The .itertuples() pandas method is a good tool for this as it provides access to every field. For brevity we'll assign the names i, lb and rv to the index, label and review columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-L9PKDBHPCN"
      },
      "source": [
        "#Get the index of the rows of review column filled with spaces\n",
        "\n",
        "blanks = []\n",
        "\n",
        "for i,lb,rv in df.itertuples():\n",
        "  if rv.isspace():\n",
        "    blanks.append(i)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vse_lyqEHRyn",
        "outputId": "dbcc0277-707a-4838-d3db-1669e5495443"
      },
      "source": [
        "blanks"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[57,\n",
              " 71,\n",
              " 147,\n",
              " 151,\n",
              " 283,\n",
              " 307,\n",
              " 313,\n",
              " 323,\n",
              " 343,\n",
              " 351,\n",
              " 427,\n",
              " 501,\n",
              " 633,\n",
              " 675,\n",
              " 815,\n",
              " 851,\n",
              " 977,\n",
              " 1079,\n",
              " 1299,\n",
              " 1455,\n",
              " 1493,\n",
              " 1525,\n",
              " 1531,\n",
              " 1763,\n",
              " 1851,\n",
              " 1905,\n",
              " 1993]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22tuQcjWJdNw"
      },
      "source": [
        "Next we'll pass our list of index numbers to the .drop() method, and set inplace=True to make the change permanent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLWJODP5HUj0"
      },
      "source": [
        "df.drop(blanks,inplace=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFi5DPN5HXMX",
        "outputId": "ed39fd5b-63c3-48c3-e2d1-56185646049d"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1938"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09uncJYsJjJr"
      },
      "source": [
        "We dropped 62 records from the original 2000. Let's continue with the analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjPj86H1JxT9"
      },
      "source": [
        "**Split the data into train & test sets:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHZAdQpZHZ7l"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAY4xOvnHcbd"
      },
      "source": [
        "x = df[\"review\"]\n",
        "\n",
        "y = df[\"label\"]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPIQiVVYHfQB"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl1pXZ72J_Gt"
      },
      "source": [
        "**Build pipelines to vectorize the data, then train and fit a model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fCM_5m9Hh0c"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97I50N1hHkr6"
      },
      "source": [
        "# Naïve Bayes:\n",
        "text_clf_nb = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "                     ('clf', MultinomialNB()),\n",
        "])\n",
        "\n",
        "# Linear SVC:\n",
        "text_clf_lsvc = Pipeline([(\"tfidf\",TfidfVectorizer()),(\"clf\",LinearSVC())])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb8rHTQFKbsr"
      },
      "source": [
        "**Feed the training data through the first pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYSEk0TbKa0r",
        "outputId": "711850d3-ff55-4bb9-ce8d-bda20d6f13ee"
      },
      "source": [
        "text_clf_nb.fit(x_train, y_train)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_LaD6LDKsQt"
      },
      "source": [
        "**Run predictions and analyze the results (naïve Bayes)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiU9w-0kKqWn"
      },
      "source": [
        "# Form a prediction set\n",
        "predictions = text_clf_nb.predict(x_test)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsBo_LovLJX9",
        "outputId": "42ecb228-7fe9-4638-efbf-71b5f3444180"
      },
      "source": [
        "# Report the confusion matrix\n",
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[259  23]\n",
            " [102 198]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6t7nQggLPI3",
        "outputId": "7ba403b0-3b14-4336-eadd-6c65a05da6a8"
      },
      "source": [
        "# Print a classification report\n",
        "print(metrics.classification_report(y_test,predictions))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.72      0.92      0.81       282\n",
            "         pos       0.90      0.66      0.76       300\n",
            "\n",
            "    accuracy                           0.79       582\n",
            "   macro avg       0.81      0.79      0.78       582\n",
            "weighted avg       0.81      0.79      0.78       582\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0sFFccVLVpj",
        "outputId": "392800da-c424-4f44-d1fd-bf2d485cdde6"
      },
      "source": [
        "# Print the overall accuracy\n",
        "print(metrics.accuracy_score(y_test,predictions))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7852233676975945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4BvV450LX8Q"
      },
      "source": [
        "Naïve Bayes gave us better-than-average results at 78.5% for classifying reviews as positive or negative based on text alone. Let's see if we can do better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjGz5J0ELfp6"
      },
      "source": [
        "**Feed the training data through the second pipeline**\n",
        "\n",
        "Next we'll run Linear SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaIgRMW-HngR",
        "outputId": "c3876891-073a-484b-f69e-d34f03d60ab8"
      },
      "source": [
        "text_clf_lsvc.fit(x_train,y_train)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQBWv989Lvmh"
      },
      "source": [
        "Run predictions and analyze the results (Linear SVC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t85Glp_HHqA-"
      },
      "source": [
        "predictions = text_clf_lsvc.predict(x_test)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-hX67jnHsc8"
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiI-8imhHuuu",
        "outputId": "ad68a7c9-31e3-49a0-e98c-b4e0eb076eed"
      },
      "source": [
        "print(metrics.confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[235  47]\n",
            " [ 41 259]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAlG9IfjHw_u",
        "outputId": "b20e55c2-0870-488e-a3ea-d387d5c3a4ae"
      },
      "source": [
        "print(metrics.classification_report(y_test,predictions))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.85      0.83      0.84       282\n",
            "         pos       0.85      0.86      0.85       300\n",
            "\n",
            "    accuracy                           0.85       582\n",
            "   macro avg       0.85      0.85      0.85       582\n",
            "weighted avg       0.85      0.85      0.85       582\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytWXWD_0Hz-k",
        "outputId": "eaff7c39-052b-46c1-a808-7378a027af9f"
      },
      "source": [
        "metrics.accuracy_score(y_test,predictions)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8487972508591065"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHsGORseH2Su",
        "outputId": "b030de18-0731-43f8-a01b-92c4fb8a68a8"
      },
      "source": [
        "text_clf.predict([\"This movie is very Good\"])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['pos'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em7EkEu7MCHb"
      },
      "source": [
        "Not bad! Based on text alone we correctly classified reviews as positive or negative 84.8% of the time. In an upcoming section we'll try to improve this score even further by performing sentiment analysis on the reviews."
      ]
    }
  ]
}